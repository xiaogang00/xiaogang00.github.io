---
layout: post
title: Learning note for mask RCNN
category: Computer Vision
tags: computer_vision
---

* content
{:toc}


### paper的主要思想和目的

文章的主要思路是把原有的Faster-RCNN进行扩展，添加一个分支使用现有的检测器对目标进行并行预测。同时，这个网络结构比较容易实现和训练，速度$5fps$也算比较快，可以很方便的应用到其他的领域，像目标检测，分割，和人物关键点检测等。并且比着现有的算法效果都要好。

**简单来说，目的就是**：

用于 **目标实例分割** 的框架（ *Object instance segmentation* ），能够有效地检测图像中的目标，同时还能为每个实例生成一个高质量的 **分割掩码**（ *segmentation mask*）。即：目标实例分割可以看做由 **object detection** 和 **semantic segmentation** 组成。



### 框架总览

实例分割的难度在于要先对一张图片所有的目标进行正确的检测同时还要对每个示例进行分割。检测的目的是把每一个单个目标分类然后用bounding box标定出来，而实例分割的目的是区分每一个像素为不同的分类而不用区别不同的目标。 Mask RCNN的框架如下：

![faster_RCNN]({{ site.url }}/images/mask_RCNN.png) 



可以看出有两个分支（两个分支是平行/并行的）：

1. 第一个分支是原始的Faster R-CNN结构，用于对候选bounding box进行分类和bbox坐标回归。

2. 第二个分支对每个ROI区域预测分割mask, 它的结构实质上是一个小的FCN。

   ​

### 主要思想

首先对图片做检测，找出图像中的ROI，对每一个ROI使用ROIAlign进行像素校正，然后对每一个ROI使用设计的FCN框架进行预测不同的实例所属分类，最终得到图像实例分割结果。 介绍一下网络使用的损失函数为分类误差+检测误差+分割误差：


$$
L = L_{cls} + L_{box} +L_{mask}
$$


分割误差是在这里提出的新的概念，对于每一个ROI，mask分支定义一个$Km^2$维的矩阵表示K个不同的分类器对于每一个$m\times m$的区域，对于每一个类都有一个。对于每一个像素，都是用sigmod函数进行求相对熵，得到平均相对熵误差$L_{mask}$。对于每一个ROI，如果检测得到ROI属于哪一个分类，就只使用哪一个分支的相对熵误差作为误差值进行计算。（举例说明：分类有3类（猫，狗，人），检测得到当前ROI属于“人”这一类，那么所使用的Lmask为“人”这一分支的mask。）这样的定义使得我们的网络不需要去区分每一个像素属于哪一类，只需要去区别在这个类是当中的不同分别小类中的哪一个。

Faster R-CNN：包含两个部分，提出RPN区域，找到目标框，对ROI进行分类。核心思想就是把图片区域内容送给深度网络，然后提取出深度网络某层的特征，并用这个特征来判断是什么物体，最后再对是物体的区域进行微调。

ROIAlign：RoI Pooling就是实现从原图区域映射到卷积区域最后pooling到固定大小的功能，把该区域的尺寸归一化成卷积网络输入的尺寸。在归一化的过程当中，会存在ROI和提取的特征不重合现象出现，作者就提出了这个概念ROIAlign，使用ROIAlign层对提取的特征和输入之间进行校准。 改变：我们避免对每一个ROI边界或者块进行数字化。使用双线性内插法计算在ROI 块当中固定的四个采样位置得到的输入特征值并对结果进行融合。

Network Architecture 分成三个部分进行，第一个是主干网络用来进行特征提取，第二个是头结构用来做边界框识别（分类和回归），第三个就是mask预测用来对每一个ROI进行区分。

