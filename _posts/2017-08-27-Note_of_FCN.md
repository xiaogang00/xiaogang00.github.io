---
layout: post
title: Learning note for FCN
category: Computer Vision
tags: computer_vision
---

* content
{:toc}




FCN在这里指的是全卷积神经网络(**Fully Convolutional Networks**)，提出这个网络框架的论文在$CVPR2015$上获得best paper的提名。其主要的作用是在对图像进行语义分割的方面。



### CNN与FCN的联系与区别

通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature  map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率），比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。

FCN对图像进行像素级的分类，从而解决了语义级别的图像分割（semantic segmentation）问题。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。

最后逐个像素计算softmax分类的损失, 相当于每一个像素对应一个训练样本。下图是Longjon用于语义分割所采用的全卷积网络(FCN)的结构示意图：

![faster_RCNN]({{ site.url }}/images/FCN.png) 

综上所述，FCN与CNN的区域在把于CNN最后的全连接层换成卷积层，输出的是一张已经Label好的图片。



### 像素级别的分割

在CNN提出之后，有许多人也提出过基于CNN的分割方法，利用CNN强大的局部特征提取能力，为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入用于训练和预测。这种方法有几个缺点：一是存储开销很大。例如对每个像素使用的图像块的大小为$15\times 15$，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。

而全卷积网络(FCN)则是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。



### 全连接层转为卷积层

全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数。然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的。因此，将此两者相互转化是可能的：

1. 对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层。权重矩阵是一个巨大的矩阵，除了某些特定块，其余部分都是零。而在其中大部分块中，元素都是相等的；
2. 相反，任何全连接层都可以被转化为卷积层。

但是卷积跟全连接是不一样的概念和计算过程，使用的是之前CNN已经训练好的权值和偏置，但是不一样的在于权值和偏置是有自己的范围，属于自己的一个卷积核。因此FCN网络中所有的层都是卷积层，故称为全卷积网络。

经过多次卷积和pooling以后，得到的图像越来越小，分辨率越来越低。当图片是最小的一层时，所产生图叫做heatmap热图，热图就是我们最重要的高维特诊图，得到高维特征的heatmap之后就是最重要的一步也是最后的一步对原图像进行upsampling，把图像进行放大、放大、放大，到原图像的大小。



### upsampling

假设现在我们有$\frac{1}{32}$尺寸的heatMap，$frac{1}{16}$尺寸的featureMap和$frac{1}{8}$寸的featureMap，$frac{1}{32}$尺寸的heatMap进行upsampling操作之后，因为这样的操作还原的图片仅仅是conv5中的卷积核中的特征，限于精度问题不能够很好地还原图像当中的特征，因此在这里向前迭代。把conv4中的卷积核对上一次upsampling之后的图进行反卷积补充细节（相当于一个差值过程），最后把conv3中的卷积核对刚才upsampling之后的图像进行再次反卷积补充细节，最后就完成了整个图像的还原。



总结：

一般来说，FCN这个网络确实是一个很好的创新，能够end-to-end的图像语义的分割，并且使用了upsampling 和skip layers等有效的结构创新。

但是还是有一些缺点需要我们想办法去解决：

1. 是得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。
2. 是对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。

